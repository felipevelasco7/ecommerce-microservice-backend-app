# Gu√≠a de Despliegue - E-commerce Microservices en Google Kubernetes Engine (GKE)

## √çndice
1. [Configuraci√≥n Inicial de GCP](#1-configuraci√≥n-inicial-de-gcp)
2. [Creaci√≥n del Cl√∫ster GKE](#2-creaci√≥n-del-cl√∫ster-gke)
3. [Preparaci√≥n de Namespaces](#3-preparaci√≥n-de-namespaces)
4. [Despliegue de PostgreSQL](#4-despliegue-de-postgresql)
5. [Construcci√≥n de Im√°genes Docker](#5-construcci√≥n-de-im√°genes-docker)
6. [Despliegue de Servicios Core](#6-despliegue-de-servicios-core)
7. [Migraci√≥n de Scripts SQL a PostgreSQL](#7-migraci√≥n-de-scripts-sql-a-postgresql)
8. [Despliegue de User Service](#8-despliegue-de-user-service)
9. [Verificaci√≥n del Sistema](#9-verificaci√≥n-del-sistema)
10. [Troubleshooting](#10-troubleshooting)

---

## 1. Configuraci√≥n Inicial de GCP

### 1.1 Instalar Google Cloud SDK (macOS)

```bash
# Descargar e instalar gcloud CLI
curl https://sdk.cloud.google.com | bash

# Reiniciar el shell
exec -l $SHELL

# Verificar instalaci√≥n
gcloud --version
```

### 1.2 Inicializar y Autenticar

```bash
# Inicializar gcloud
gcloud init

# Autenticar con tu cuenta de Google
gcloud auth login

# Configurar proyecto
export PROJECT_ID="ecommerce-microservices-final"
gcloud config set project $PROJECT_ID

# Si el proyecto no existe, crearlo
gcloud projects create $PROJECT_ID --name="E-commerce Microservices"
```

### 1.3 Habilitar APIs Necesarias

```bash
# Habilitar APIs de Google Cloud
gcloud services enable container.googleapis.com
gcloud services enable containerregistry.googleapis.com
gcloud services enable cloudbuild.googleapis.com
```

---

## 2. Creaci√≥n del Cl√∫ster GKE

### 2.1 Crear Cl√∫ster

```bash
# Crear cl√∫ster GKE con autoscaling
gcloud container clusters create ecommerce-cluster \
    --zone=us-central1-a \
    --num-nodes=3 \
    --machine-type=e2-medium \
    --disk-size=20 \
    --enable-autoscaling \
    --min-nodes=2 \
    --max-nodes=5 \
    --enable-autorepair \
    --enable-autoupgrade
```

**Tiempo estimado:** 5-7 minutos

### 2.2 Conectar kubectl al Cl√∫ster

```bash
# Obtener credenciales del cl√∫ster
gcloud container clusters get-credentials ecommerce-cluster --zone=us-central1-a

# Verificar conexi√≥n
kubectl cluster-info
kubectl get nodes
```

**Verificaci√≥n esperada:** Deber√≠as ver 3 nodos en estado `Ready`

---

## 3. Preparaci√≥n de Namespaces

### 3.1 Crear Estructura de Directorios

```bash
cd ecommerce-microservice-backend-app
mkdir -p k8s/{namespaces,configmaps,secrets,deployments,services}
```

### 3.2 Crear Archivo de Namespaces

```bash
cat > k8s/namespaces/namespaces.yaml <<'EOF'
apiVersion: v1
kind: Namespace
metadata:
  name: dev
  labels:
    name: dev
    environment: development
---
apiVersion: v1
kind: Namespace
metadata:
  name: qa
  labels:
    name: qa
    environment: quality-assurance
---
apiVersion: v1
kind: Namespace
metadata:
  name: prod
  labels:
    name: prod
    environment: production
EOF
```

### 3.3 Aplicar Namespaces

```bash
kubectl apply -f k8s/namespaces/namespaces.yaml

# Verificar
kubectl get namespaces
```

---

## 4. Despliegue de PostgreSQL

### 4.1 Crear Configuraci√≥n de PostgreSQL

```bash
cat > k8s/deployments/postgres.yaml <<'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: dev
data:
  POSTGRES_USER: ecommerce
  POSTGRES_DB: ecommerce_db
  POSTGRES_MULTIPLE_DATABASES: user_db,product_db,order_db,payment_db,shipping_db,favourite_db
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-initdb
  namespace: dev
data:
  init-databases.sh: |
    #!/bin/bash
    set -e
    psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" --dbname "$POSTGRES_DB" <<-EOSQL
        CREATE DATABASE user_db;
        CREATE DATABASE product_db;
        CREATE DATABASE order_db;
        CREATE DATABASE payment_db;
        CREATE DATABASE shipping_db;
        CREATE DATABASE favourite_db;
        GRANT ALL PRIVILEGES ON DATABASE user_db TO $POSTGRES_USER;
        GRANT ALL PRIVILEGES ON DATABASE product_db TO $POSTGRES_USER;
        GRANT ALL PRIVILEGES ON DATABASE order_db TO $POSTGRES_USER;
        GRANT ALL PRIVILEGES ON DATABASE payment_db TO $POSTGRES_USER;
        GRANT ALL PRIVILEGES ON DATABASE shipping_db TO $POSTGRES_USER;
        GRANT ALL PRIVILEGES ON DATABASE favourite_db TO $POSTGRES_USER;
    EOSQL
---
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
  namespace: dev
type: Opaque
data:
  POSTGRES_PASSWORD: ZWNvbW1lcmNlMTIz # ecommerce123 en base64
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: dev
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:13-alpine
        ports:
        - containerPort: 5432
        envFrom:
        - configMapRef:
            name: postgres-config
        - secretRef:
            name: postgres-secret
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
          subPath: postgres
        - name: initdb
          mountPath: /docker-entrypoint-initdb.d
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: initdb
        configMap:
          name: postgres-initdb
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 5Gi
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: dev
spec:
  selector:
    app: postgres
  ports:
    - port: 5432
      targetPort: 5432
  clusterIP: None
EOF
```

### 4.2 Desplegar PostgreSQL

```bash
kubectl apply -f k8s/deployments/postgres.yaml

# Esperar a que est√© listo
kubectl wait --for=condition=ready pod/postgres-0 -n dev --timeout=180s

# Verificar bases de datos creadas
kubectl exec -n dev postgres-0 -- psql -U ecommerce -c '\l'
```

**Bases de datos esperadas:**
- ecommerce_db
- user_db
- product_db
- order_db
- payment_db
- shipping_db
- favourite_db

---

## 5. Construcci√≥n de Im√°genes Docker

### 5.1 Actualizar Dockerfiles

Todos los servicios necesitan usar una imagen base v√°lida.

```bash
# Actualizar Dockerfile de service-discovery
cat > service-discovery/Dockerfile <<'EOF'
FROM eclipse-temurin:11-jre-alpine

LABEL maintainer="ecommerce-project"

WORKDIR /app

ARG JAR_FILE=service-discovery/target/*.jar
COPY ${JAR_FILE} app.jar

EXPOSE 8761

ENTRYPOINT ["java", "-jar", "app.jar"]
EOF
```

**Repetir para todos los servicios**, ajustando el puerto EXPOSE seg√∫n:
- service-discovery: 8761
- cloud-config: 9296
- api-gateway: 8080
- proxy-client: 8900
- user-service: 8700
- product-service: 8500
- order-service: 8300
- payment-service: 8400
- shipping-service: 8600
- favourite-service: 8800

### 5.2 Crear Archivo de Cloud Build para User Service

```bash
cat > cloudbuild-user-service.yaml <<'EOF'
steps:
  # Build user-service SIN CACH√â
  - name: 'gcr.io/cloud-builders/mvn'
    args: ['clean', 'package', '-pl', 'user-service', '-am', '-DskipTests', '-U']
  
  - name: 'gcr.io/cloud-builders/docker'
    args: 
      - 'build'
      - '--no-cache'
      - '-t'
      - 'gcr.io/$PROJECT_ID/user-service:0.1.0'
      - '-t'
      - 'gcr.io/$PROJECT_ID/user-service:latest'
      - '-f'
      - 'user-service/Dockerfile'
      - '.'

images:
  - 'gcr.io/$PROJECT_ID/user-service:0.1.0'
  - 'gcr.io/$PROJECT_ID/user-service:latest'

timeout: 600s
options:
  machineType: 'E2_HIGHCPU_8'
EOF
```

### 5.3 Configurar Docker para GCR

```bash
gcloud auth configure-docker
```

---

## 6. Despliegue de Servicios Core

### 6.1 Service Discovery (Eureka)

```bash
cat > k8s/deployments/service-discovery.yaml <<'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: service-discovery
  namespace: dev
  labels:
    app: service-discovery
spec:
  replicas: 1
  selector:
    matchLabels:
      app: service-discovery
  template:
    metadata:
      labels:
        app: service-discovery
    spec:
      containers:
      - name: service-discovery
        image: gcr.io/PROJECT_ID/service-discovery:0.1.0
        ports:
        - containerPort: 8761
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "dev"
        - name: EUREKA_INSTANCE_HOSTNAME
          value: "service-discovery"
        - name: EUREKA_CLIENT_REGISTER_WITH_EUREKA
          value: "false"
        - name: EUREKA_CLIENT_FETCH_REGISTRY
          value: "false"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8761
          initialDelaySeconds: 90
          periodSeconds: 10
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8761
          initialDelaySeconds: 60
          periodSeconds: 5
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: service-discovery
  namespace: dev
spec:
  selector:
    app: service-discovery
  ports:
    - protocol: TCP
      port: 8761
      targetPort: 8761
  type: ClusterIP
EOF
```

**Desplegar:**

```bash
export PROJECT_ID=$(gcloud config get-value project)
sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/service-discovery.yaml | kubectl apply -f -

# Verificar
kubectl get pods -n dev -w
```

### 6.2 Cloud Config Server

```bash
cat > k8s/deployments/cloud-config.yaml <<'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloud-config
  namespace: dev
  labels:
    app: cloud-config
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloud-config
  template:
    metadata:
      labels:
        app: cloud-config
    spec:
      containers:
      - name: cloud-config
        image: gcr.io/PROJECT_ID/cloud-config:0.1.0
        ports:
        - containerPort: 9296
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "dev"
        - name: EUREKA_CLIENT_SERVICEURL_DEFAULTZONE
          value: "http://service-discovery:8761/eureka/"
        - name: EUREKA_INSTANCE_PREFER_IP_ADDRESS
          value: "true"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 9296
          initialDelaySeconds: 90
          periodSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 9296
          initialDelaySeconds: 60
          periodSeconds: 5
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: cloud-config
  namespace: dev
spec:
  selector:
    app: cloud-config
  ports:
    - protocol: TCP
      port: 9296
      targetPort: 9296
  type: ClusterIP
EOF
```

**Desplegar:**

```bash
sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/cloud-config.yaml | kubectl apply -f -
```

---

## 7. Migraci√≥n de Scripts SQL a PostgreSQL

Los scripts de Flyway est√°n escritos para MySQL y deben convertirse a sintaxis PostgreSQL.

### 7.1 Cambios Necesarios

**MySQL ‚Üí PostgreSQL:**
- `INT(11) AUTO_INCREMENT` ‚Üí `SERIAL`
- `INT(11)` ‚Üí `INTEGER`
- `LOCALTIMESTAMP NULL_TO_DEFAULT` ‚Üí `CURRENT_TIMESTAMP`
- `DEFAULT false` ‚Üí `DEFAULT false` (sin cambios en BOOLEAN)

### 7.2 Actualizar application-dev.yml

```bash
cat > user-service/src/main/resources/application-dev.yml <<'EOF'
server:
  port: 8700

management:
  endpoints:
    web:
      exposure:
        include: "*"

spring:
  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5432/user_db}
    username: ${SPRING_DATASOURCE_USERNAME:ecommerce}
    password: ${SPRING_DATASOURCE_PASSWORD:ecommerce123}
    driver-class-name: org.postgresql.Driver
  jpa:
    show-sql: true
    hibernate:
      ddl-auto: update
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        use_sql_comments: true
        format_sql: true

logging:
  level:
    org:
      hibernate:
        SQL: DEBUG
      springframework:
        web: DEBUG
        data: DEBUG
      boot:
        autoconfigure:
          data:
            rest: DEBUG
            jpa: DEBUG
            orm: DEBUG
EOF
```

### 7.3 Actualizar Scripts de Migraci√≥n

**V1 - create_users_table.sql:**

```sql
CREATE TABLE IF NOT EXISTS users (
    user_id SERIAL PRIMARY KEY,
    first_name VARCHAR(255),
    last_name VARCHAR(255),
    image_url VARCHAR(255) DEFAULT 'https://bootdey.com/img/Content/avatar/avatar7.png',
    email VARCHAR(255) DEFAULT 'springxyzabcboot@gmail.com',
    phone VARCHAR(255) DEFAULT '+21622125144',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at TIMESTAMP
);
```

**V3 - create_address_table.sql:**

```sql
CREATE TABLE IF NOT EXISTS address (
    address_id SERIAL PRIMARY KEY,
    user_id INTEGER,
    full_address VARCHAR(255),
    postal_code VARCHAR(255),
    city VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at TIMESTAMP
);
```

**V5 - create_credentials_table.sql:**

```sql
CREATE TABLE IF NOT EXISTS credentials (
    credential_id SERIAL PRIMARY KEY,
    user_id INTEGER,
    username VARCHAR(255),
    password VARCHAR(255),
    role VARCHAR(255),
    is_enabled BOOLEAN DEFAULT false,
    is_account_non_expired BOOLEAN DEFAULT true,
    is_account_non_locked BOOLEAN DEFAULT true,
    is_credentials_non_expired BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at TIMESTAMP
);
```

**V7 - create_verification_tokens_table.sql:**

```sql
CREATE TABLE IF NOT EXISTS verification_tokens (
    verification_token_id SERIAL PRIMARY KEY,
    credential_id INTEGER,
    verif_token VARCHAR(255),
    expire_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at TIMESTAMP
);
```

### 7.4 Script Automatizado para Actualizar Migraciones

Usa el script `scr.sh` incluido en el repositorio que actualiza autom√°ticamente todos los archivos SQL.

---

## 8. Despliegue de User Service

### 8.1 Crear ConfigMaps y Secrets

```bash
cat > k8s/deployments/user-service.yaml <<'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: user-service-config
  namespace: dev
data:
  SPRING_PROFILES_ACTIVE: "dev"
  EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: "http://service-discovery:8761/eureka/"
  SPRING_CONFIG_IMPORT: "optional:configserver:http://cloud-config:9296/"
  SPRING_DATASOURCE_URL: "jdbc:postgresql://postgres:5432/user_db"
  SPRING_DATASOURCE_USERNAME: "ecommerce"
  SPRING_JPA_HIBERNATE_DDL_AUTO: "update"
---
apiVersion: v1
kind: Secret
metadata:
  name: user-service-secret
  namespace: dev
type: Opaque
data:
  SPRING_DATASOURCE_PASSWORD: ZWNvbW1lcmNlMTIz # ecommerce123
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  namespace: dev
  labels:
    app: user-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
    spec:
      initContainers:
      - name: wait-for-eureka
        image: busybox:1.36
        command: ['sh', '-c', 'until wget -qO- http://service-discovery:8761/actuator/health 2>/dev/null; do echo "waiting for eureka..."; sleep 3; done; echo "eureka is up"']
      - name: wait-for-postgres
        image: postgres:13-alpine
        command: ['sh', '-c', 'until PGPASSWORD=ecommerce123 psql -h postgres -U ecommerce -d user_db -c "\\q" 2>/dev/null; do echo "waiting for postgres..."; sleep 3; done; echo "postgres is up"']
      containers:
      - name: user-service
        image: gcr.io/PROJECT_ID/user-service:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8700
        envFrom:
        - configMapRef:
            name: user-service-config
        - secretRef:
            name: user-service-secret
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /user-service/actuator/health/liveness
            port: 8700
          initialDelaySeconds: 120
          periodSeconds: 10
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /user-service/actuator/health/readiness
            port: 8700
          initialDelaySeconds: 90
          periodSeconds: 5
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: user-service
  namespace: dev
spec:
  selector:
    app: user-service
  ports:
    - protocol: TCP
      port: 8700
      targetPort: 8700
  type: ClusterIP
EOF
```

### 8.2 Construir Imagen Docker

```bash
# Construir imagen en Cloud Build
gcloud builds submit --config=cloudbuild-user-service.yaml .
```

**Tiempo estimado:** 3-5 minutos

### 8.3 Desplegar User Service

```bash
export PROJECT_ID=$(gcloud config get-value project)
sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/user-service.yaml | kubectl apply -f -

# Monitorear el despliegue
kubectl get pods -n dev -w

# Ver logs
kubectl logs -n dev -f -l app=user-service -c user-service
```

---

## 9. Verificaci√≥n del Sistema

### 9.1 Verificar Estado de Pods

```bash
kubectl get pods -n dev
```

**Estado esperado:**
```
NAME                                READY   STATUS    RESTARTS   AGE
cloud-config-xxxxx                  1/1     Running   0          Xm
postgres-0                          1/1     Running   0          Xm
service-discovery-xxxxx             1/1     Running   0          Xm
user-service-xxxxx                  1/1     Running   0          Xm
```

### 9.2 Verificar Servicios

```bash
kubectl get svc -n dev
```

### 9.3 Verificar Eureka Dashboard

```bash
# Port-forward a Eureka
kubectl port-forward -n dev svc/service-discovery 8761:8761

# Abrir en navegador: http://localhost:8761
```

**Servicios registrados esperados:**
- SERVICE-DISCOVERY
- CLOUD-CONFIG
- USER-SERVICE

### 9.4 Verificar Base de Datos

```bash
# Ver bases de datos
kubectl exec -n dev postgres-0 -- psql -U ecommerce -c '\l'

# Ver tablas de user_db
kubectl exec -n dev postgres-0 -- psql -U ecommerce -d user_db -c '\dt'

# Ver datos de usuarios
kubectl exec -n dev postgres-0 -- psql -U ecommerce -d user_db -c "SELECT * FROM users;"
```

### 9.5 Ver Logs

```bash
# Logs de user-service
kubectl logs -n dev -l app=user-service

# Logs en tiempo real
kubectl logs -n dev -f -l app=user-service -c user-service
```

---

## 10. Troubleshooting

### Error: Failed to load driver class org.postgresql.Driver

**Causa:** El driver de PostgreSQL no est√° incluido en el JAR o la imagen Docker est√° usando cach√© vieja.

**Soluci√≥n:**
```bash
# Verificar que pom.xml tenga la dependencia
grep -A 3 "postgresql" user-service/pom.xml

# Rebuild sin cach√©
gcloud builds submit --config=cloudbuild-user-service.yaml .

# Forzar pull de nueva imagen
kubectl delete deployment user-service -n dev
kubectl apply -f k8s/deployments/user-service.yaml
```

### Error: Flyway migration failed - syntax error

**Causa:** Scripts SQL tienen sintaxis de MySQL en lugar de PostgreSQL.

**Soluci√≥n:**
```bash
# Ejecutar script de correcci√≥n
./scr.sh

# O manualmente actualizar archivos seg√∫n la secci√≥n 7.3
```

### Error: Pod stuck in "Init:2/3"

**Causa:** El init container no puede conectarse a la base de datos.

**Soluci√≥n:**
```bash
# Verificar que la base de datos existe
kubectl exec -n dev postgres-0 -- psql -U ecommerce -c '\l' | grep user_db

# Si no existe, crearla manualmente
kubectl exec -n dev postgres-0 -- psql -U ecommerce -d postgres -c "CREATE DATABASE user_db;"
```

### Error: CrashLoopBackOff

**Soluci√≥n:**
```bash
# Ver logs del pod fallido
kubectl logs -n dev <pod-name> --previous

# Ver eventos
kubectl describe pod -n dev <pod-name>

# Ver logs de init containers
kubectl logs -n dev <pod-name> -c wait-for-eureka
kubectl logs -n dev <pod-name> -c wait-for-postgres
```

### Limpiar y Reiniciar

Si necesitas empezar desde cero:

```bash
# Eliminar todos los recursos del namespace dev
kubectl delete namespace dev

# Recrear namespace
kubectl apply -f k8s/namespaces/namespaces.yaml

# Empezar desde el paso 4
```

---

## Comandos √ötiles

### Ver todos los recursos

```bash
kubectl get all -n dev
```

### Ver uso de recursos

```bash
kubectl top nodes
kubectl top pods -n dev
```

### Port-forward a un servicio

```bash
kubectl port-forward -n dev svc/service-discovery 8761:8761
kubectl port-forward -n dev svc/user-service 8700:8700
```

### Ejecutar comando en pod

```bash
kubectl exec -it -n dev postgres-0 -- psql -U ecommerce -d user_db
```

### Ver configuraci√≥n de un deployment

```bash
kubectl get deployment user-service -n dev -o yaml
```

### Escalar un deployment

```bash
kubectl scale deployment user-service -n dev --replicas=2
```

### Ver logs de Cloud Build

```bash
gcloud builds list
gcloud builds log <BUILD_ID>
```

---

## 11. Despliegue de Microservicios de Negocio

Esta secci√≥n documenta el despliegue de los 5 microservicios principales: Product, Order, Payment, Shipping y Favourite.

### 11.1 Preparaci√≥n Com√∫n para Todos los Servicios

#### 11.1.1 Actualizar Dependencias en pom.xml

Agregar el driver de PostgreSQL a cada servicio (product, order, payment, shipping, favourite):

```xml
<dependency>
    <groupId>org.postgresql</groupId>
    <artifactId>postgresql</artifactId>
    <scope>runtime</scope>
</dependency>
```

#### 11.1.2 Actualizar application-dev.yml

Actualizar la configuraci√≥n de cada servicio para usar PostgreSQL y conectarse a Cloud Config:

```yaml
server:
  port: 8500  # Cambiar seg√∫n servicio

management:
  endpoints:
    web:
      exposure:
        include: "*"

spring:
  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5432/product_db}
    username: ${SPRING_DATASOURCE_USERNAME:ecommerce}
    password: ${SPRING_DATASOURCE_PASSWORD:ecommerce123}
    driver-class-name: org.postgresql.Driver
  jpa:
    show-sql: true
    hibernate:
      ddl-auto: none  # Importante: usar 'none' para evitar conflictos con Flyway
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        use_sql_comments: true
        format_sql: true
  flyway:
    enabled: true
    baseline-on-migrate: true

logging:
  level:
    org:
      hibernate:
        SQL: DEBUG
      springframework:
        web: DEBUG
```

**Puertos por servicio:**
- product-service: 8500
- order-service: 8300
- payment-service: 8400
- shipping-service: 8600
- favourite-service: 8800

**Bases de datos por servicio:**
- product-service: product_db
- order-service: order_db
- payment-service: payment_db
- shipping-service: shipping_db
- favourite-service: favourite_db

#### 11.1.3 Migrar Scripts Flyway a PostgreSQL

**Cambios necesarios en cada archivo SQL de Flyway:**

```sql
-- ANTES (MySQL)
user_id INT(11) AUTO_INCREMENT PRIMARY KEY,
price_unit DECIMAL(10,2),
is_verified BOOLEAN DEFAULT false,
created_at LOCALTIMESTAMP NULL_TO_DEFAULT

-- DESPU√âS (PostgreSQL)
user_id SERIAL PRIMARY KEY,
price_unit NUMERIC(10,2),
is_verified BOOLEAN DEFAULT false,
created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL
```

**Script automatizado para actualizar:**

```bash
# Ejecutar desde la ra√≠z del proyecto
./scr.sh
```

O manualmente con sed:

```bash
for service in product-service order-service payment-service shipping-service favourite-service; do
  find $service/src/main/resources/db/migration -name "*.sql" -exec sed -i '' \
    -e 's/INT(11) AUTO_INCREMENT/SERIAL/g' \
    -e 's/INT(11)/INTEGER/g' \
    -e 's/DECIMAL/NUMERIC/g' \
    -e 's/LOCALTIMESTAMP NULL_TO_DEFAULT/CURRENT_TIMESTAMP NOT NULL/g' {} \;
done
```

### 11.2 Crear ConfigMaps y Secrets

Para cada servicio, crear el ConfigMap con la configuraci√≥n del Cloud Config Server:

```bash
cat > k8s/configmaps/product-service-config.yaml <<'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: product-service-config
  namespace: dev
data:
  SPRING_PROFILES_ACTIVE: "dev"
  EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: "http://service-discovery:8761/eureka/"
  SPRING_CONFIG_IMPORT: "optional:configserver:http://cloud-config:9296"
  SPRING_DATASOURCE_URL: "jdbc:postgresql://postgres:5432/product_db"
  SPRING_DATASOURCE_USERNAME: "ecommerce"
  SPRING_JPA_HIBERNATE_DDL_AUTO: "none"
EOF
```

Crear el Secret:

```bash
cat > k8s/secrets/product-service-secret.yaml <<'EOF'
apiVersion: v1
kind: Secret
metadata:
  name: product-service-secret
  namespace: dev
type: Opaque
data:
  SPRING_DATASOURCE_PASSWORD: ZWNvbW1lcmNlMTIz # ecommerce123
EOF
```

**Repetir para cada servicio:** order, payment, shipping, favourite

### 11.3 Crear Cloud Build Configurations

Crear archivo de build para cada servicio con la flag `--no-cache`:

```bash
cat > cloudbuild-product-service.yaml <<'EOF'
steps:
  - name: 'gcr.io/cloud-builders/mvn'
    id: 'build-jar'
    args: ['clean', 'package', '-pl', 'product-service', '-am', '-DskipTests', '-U']
  
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-image'
    args: 
      - 'build'
      - '--no-cache'
      - '-t'
      - 'gcr.io/$PROJECT_ID/product-service:0.1.0'
      - '-t'
      - 'gcr.io/$PROJECT_ID/product-service:latest'
      - '-f'
      - 'product-service/Dockerfile'
      - '.'

images:
  - 'gcr.io/$PROJECT_ID/product-service:0.1.0'
  - 'gcr.io/$PROJECT_ID/product-service:latest'

timeout: 600s
options:
  machineType: 'E2_HIGHCPU_8'
EOF
```

**Repetir para:** order-service, payment-service, shipping-service, favourite-service

### 11.4 Crear Deployments de Kubernetes

Crear deployment para cada servicio con configuraci√≥n de recursos apropiada:

```bash
cat > k8s/deployments/product-service.yaml <<'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: product-service
  namespace: dev
spec:
  replicas: 1
  selector:
    matchLabels:
      app: product-service
  template:
    metadata:
      labels:
        app: product-service
    spec:
      initContainers:
      - name: wait-for-eureka
        image: busybox:1.36
        command: ['sh', '-c', 'until wget -qO- http://service-discovery:8761/actuator/health 2>/dev/null; do echo "Waiting for Eureka..."; sleep 3; done']
      - name: wait-for-postgres
        image: postgres:13-alpine
        command: ['sh', '-c', 'until PGPASSWORD=ecommerce123 psql -h postgres -U ecommerce -d product_db -c "\\q" 2>/dev/null; do echo "Waiting for PostgreSQL..."; sleep 3; done']
      containers:
      - name: product-service
        image: gcr.io/PROJECT_ID/product-service:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8500
        envFrom:
        - configMapRef:
            name: product-service-config
        - secretRef:
            name: product-service-secret
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /product-service/actuator/health/liveness
            port: 8500
          initialDelaySeconds: 120
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /product-service/actuator/health/readiness
            port: 8500
          initialDelaySeconds: 90
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: product-service
  namespace: dev
spec:
  type: ClusterIP
  selector:
    app: product-service
  ports:
  - port: 8500
    targetPort: 8500
    protocol: TCP
EOF
```

**Ajustar para cada servicio:** puertos, nombres de bases de datos, rutas de health checks

### 11.5 Script Automatizado de Despliegue

Crear script para automatizar todo el proceso:

```bash
cat > build-and-deploy-all.sh <<'EOF'
#!/bin/bash
set -e
cd "$(dirname "$0")"

PROJECT_ID=$(gcloud config get-value project)
echo "üöÄ Iniciando despliegue automatizado..."

# Lista de servicios a desplegar
SERVICES=("order-service" "payment-service" "shipping-service" "favourite-service")

for SERVICE in "${SERVICES[@]}"; do
    echo ""
    echo "======================================="
    echo "üì¶ Construyendo ${SERVICE}..."
    echo "======================================="
    
    gcloud builds submit --config=cloudbuild-${SERVICE}.yaml .
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ Build de ${SERVICE} exitoso"
        
        echo ""
        echo "üì¶ Desplegando ${SERVICE}..."
        echo "==============================="
        
        kubectl apply -f k8s/configmaps/${SERVICE}-config.yaml
        kubectl apply -f k8s/secrets/${SERVICE}-secret.yaml
        sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/${SERVICE}.yaml | kubectl apply -f -
        
        echo "‚úÖ ${SERVICE} desplegado"
    else
        echo "‚ùå Error en build de ${SERVICE}"
        exit 1
    fi
done

echo ""
echo "üéâ ¬°Proceso completado!"
echo ""
echo "üìä Estado de todos los pods:"
kubectl get pods -n dev

echo ""
echo "üîç Servicios en Eureka:"
echo "kubectl port-forward -n dev svc/service-discovery 8761:8761"
echo "Luego visita: http://localhost:8761"
EOF

chmod +x build-and-deploy-all.sh
```

### 11.6 Ejecutar Despliegue Automatizado

```bash
# Ejecutar script
./build-and-deploy-all.sh
```

**Tiempo total estimado:** 15-20 minutos para los 4 servicios

### 11.7 Resoluci√≥n de Problemas Comunes

#### Error: CrashLoopBackOff - Health Check Failures

**Problema:** El pod se reinicia constantemente antes de completar el startup.

**Causa:** Con recursos limitados (100m CPU), la aplicaci√≥n puede tardar m√°s de 5 minutos en arrancar.

**Soluci√≥n:** Aumentar tiempos de probes en el deployment:

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "200m"
startupProbe:
  httpGet:
    path: /favourite-service/actuator/health
    port: 8800
  initialDelaySeconds: 60
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 50  # 60s + (50 * 10s) = 560 segundos total
livenessProbe:
  httpGet:
    path: /favourite-service/actuator/health/liveness
    port: 8800
  initialDelaySeconds: 30
  periodSeconds: 15
  timeoutSeconds: 5
  failureThreshold: 3
readinessProbe:
  httpGet:
    path: /favourite-service/actuator/health/readiness
    port: 8800
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 3
  failureThreshold: 3
```

#### Error: Pod Stuck in Pending - Insufficient CPU

**Problema:** `0/5 nodes are available: 5 Insufficient cpu`

**Causa:** El cl√∫ster ha alcanzado su l√≠mite m√°ximo de nodos y CPU.

**Soluci√≥n 1 - Reducir recursos del pod:**

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "100m"  # Reducido de 250m
  limits:
    memory: "512Mi"
    cpu: "200m"  # Reducido de 500m
```

**Soluci√≥n 2 - Escalar el cl√∫ster:**

```bash
gcloud container clusters update ecommerce-cluster \
    --zone=us-central1-a \
    --max-nodes=8
```

#### Error: Hibernate Schema Validation Failed

**Problema:** `Schema-validation: wrong column type encountered... found [numeric], but expecting [decimal]`

**Causa:** Hibernate valida estrictamente los tipos y PostgreSQL convierte DECIMAL a NUMERIC internamente.

**Soluci√≥n:** Cambiar `ddl-auto` de `validate` a `none`:

```yaml
spring:
  jpa:
    hibernate:
      ddl-auto: none  # Dejar que Flyway maneje el schema
```

#### Verificar Tiempos de Startup

Ver cu√°nto tarda cada servicio en arrancar:

```bash
kubectl logs -n dev <pod-name> | grep "Started.*Application in"
```

Ejemplo de salida:
```
Started FavouriteServiceApplication in 337.705 seconds (JVM running for 353.196)
```

### 11.8 Verificaci√≥n Final

```bash
# Ver todos los pods
kubectl get pods -n dev

# Estado esperado:
# NAME                                 READY   STATUS    RESTARTS   AGE
# cloud-config-xxxxx                   1/1     Running   0          Xh
# favourite-service-xxxxx              1/1     Running   0          Xm
# order-service-xxxxx                  1/1     Running   0          Xm
# payment-service-xxxxx                1/1     Running   0          Xm
# postgres-0                           1/1     Running   0          Xh
# product-service-xxxxx                1/1     Running   0          Xm
# service-discovery-xxxxx              1/1     Running   0          Xh
# shipping-service-xxxxx               1/1     Running   0          Xm
# user-service-xxxxx                   1/1     Running   0          Xh

# Verificar registro en Eureka
kubectl port-forward -n dev svc/service-discovery 8761:8761
# Abrir http://localhost:8761
```

**Servicios esperados en Eureka:**
- SERVICE-DISCOVERY
- CLOUD-CONFIG
- USER-SERVICE
- PRODUCT-SERVICE
- ORDER-SERVICE
- PAYMENT-SERVICE
- SHIPPING-SERVICE
- FAVOURITE-SERVICE

### 11.9 Comandos de Limpieza

Si necesitas redeployar un servicio:

```bash
# Eliminar deployment espec√≠fico
kubectl delete deployment product-service -n dev

# Reconstruir imagen
gcloud builds submit --config=cloudbuild-product-service.yaml .

# Redesplegar
PROJECT_ID=$(gcloud config get-value project)
sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/product-service.yaml | kubectl apply -f -

# Monitorear
kubectl get pods -n dev -w
```

### 11.10 Resumen de Configuraciones Cr√≠ticas

| Servicio | Puerto | DB | CPU Request | Memory Request | Startup Time |
|----------|--------|-----|-------------|----------------|--------------|
| product-service | 8500 | product_db | 250m | 512Mi | ~90s |
| order-service | 8300 | order_db | 250m | 512Mi | ~120s |
| payment-service | 8400 | payment_db | 250m | 512Mi | ~90s |
| shipping-service | 8600 | shipping_db | 250m | 512Mi | ~100s |
| favourite-service | 8800 | favourite_db | 100m | 256Mi | ~337s |

**Nota:** favourite-service tiene recursos reducidos debido a limitaciones del cl√∫ster. Si tienes recursos disponibles, aumenta a 250m CPU / 512Mi RAM.

---

## 12. Despliegue de Proxy-Client y API Gateway

### 12.1 Contexto

Despu√©s de desplegar los 9 microservicios base, necesitamos completar la arquitectura con:
- **proxy-client**: Cliente proxy para interacciones frontend (puerto 8900)
- **api-gateway**: Gateway principal con acceso externo v√≠a LoadBalancer (puerto 8080)

### 12.2 Desaf√≠os Encontrados

#### Problema 1: Insuficiencia de Recursos CPU

Al desplegar proxy-client, el pod qued√≥ en estado `Pending`:

```bash
kubectl describe pod -n dev proxy-client-xxxxx
# Events: 0/5 nodes are available: 5 Insufficient cpu
```

**Causa:** Cl√∫ster alcanz√≥ m√°ximo de 5 nodos con CPU insuficiente para nuevos pods.

**Soluci√≥n:** Escalar el cl√∫ster aumentando el m√°ximo de nodos:

```bash
# Aumentar capacidad del cl√∫ster
gcloud container clusters update ecommerce-cluster \
    --zone=us-central1-a \
    --max-nodes=8 \
    --enable-autoscaling

# Verificar creaci√≥n de nuevo nodo
kubectl get nodes
# El autoscaler crear√° autom√°ticamente nodos adicionales (5 ‚Üí 6)
```

**Resultado:** El pod transit√≥ de `Pending` ‚Üí `Running` en ~60 segundos tras la creaci√≥n del 6¬∫ nodo.

#### Problema 2: Health Checks con 404 en Proxy-Client

El pod proxy-client entraba en `CrashLoopBackOff`:

```bash
kubectl describe pod -n dev proxy-client-xxxxx
# Events: Liveness probe failed: HTTP probe failed with statuscode: 404
#         Readiness probe failed: HTTP probe failed with statuscode: 404
```

**Causa:** La aplicaci√≥n usa contexto `/app` pero los health checks buscaban `/actuator/health`.

**Soluci√≥n:** Actualizar el deployment para incluir el contexto correcto:

```yaml
# k8s/deployments/proxy-client.yaml
livenessProbe:
  httpGet:
    path: /app/actuator/health/liveness  # A√±adir /app
    port: 8900
readinessProbe:
  httpGet:
    path: /app/actuator/health/readiness  # A√±adir /app
    port: 8900
```

#### Problema 3: Pod Duplicado de Favourite-Service

Al restaurar recursos de favourite-service (100m‚Üí250m CPU), Kubernetes cre√≥ un segundo pod fallido:

```bash
kubectl get pods -n dev
# favourite-service-8dfbcb68-24rsm    1/1     Running          0          50m
# favourite-service-99766fdcc-b8fjj   0/1     InvalidImageName 0          10m
```

**Causa:** El `sed` no reemplaz√≥ `PROJECT_ID` en la imagen del deployment, quedando:
```
image: gcr.io/PROJECT_ID/favourite-service:latest  # ‚ùå Literal incorrecto
```

**Soluci√≥n:**

```bash
# Aplicar deployment correctamente con sustituci√≥n
export PROJECT_ID=$(gcloud config get-value project)
sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/favourite-service.yaml | kubectl apply -f -

# Eliminar pod fallido
kubectl delete pod -n dev favourite-service-99766fdcc-b8fjj
```

### 12.3 Construcci√≥n de Im√°genes

#### Proxy-Client

```bash
# Crear cloudbuild-proxy-client.yaml
cat > cloudbuild-proxy-client.yaml << 'EOF'
steps:
  - name: 'maven:3.8.4-openjdk-11'
    id: 'build-jar'
    entrypoint: 'mvn'
    args: ['clean', 'package', '-DskipTests', '-pl', 'proxy-client', '-am']
  
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-image'
    args: [
      'build',
      '--no-cache',
      '-t', 'gcr.io/$PROJECT_ID/proxy-client:0.1.0',
      '-t', 'gcr.io/$PROJECT_ID/proxy-client:latest',
      '-f', 'proxy-client/Dockerfile',
      '.'
    ]

images:
  - 'gcr.io/$PROJECT_ID/proxy-client:0.1.0'
  - 'gcr.io/$PROJECT_ID/proxy-client:latest'

options:
  machineType: 'E2_HIGHCPU_8'
timeout: '600s'
EOF

# Construir imagen
gcloud builds submit --config=cloudbuild-proxy-client.yaml .
```

**Resultado:** BUILD SUCCESS en 1m31s

#### API Gateway

```bash
# Crear cloudbuild-api-gateway.yaml
cat > cloudbuild-api-gateway.yaml << 'EOF'
steps:
  - name: 'maven:3.8.4-openjdk-11'
    id: 'build-jar'
    entrypoint: 'mvn'
    args: ['clean', 'package', '-DskipTests', '-pl', 'api-gateway', '-am']
  
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-image'
    args: [
      'build',
      '--no-cache',
      '-t', 'gcr.io/$PROJECT_ID/api-gateway:0.1.0',
      '-t', 'gcr.io/$PROJECT_ID/api-gateway:latest',
      '-f', 'api-gateway/Dockerfile',
      '.'
    ]

images:
  - 'gcr.io/$PROJECT_ID/api-gateway:0.1.0'
  - 'gcr.io/$PROJECT_ID/api-gateway:latest'

options:
  machineType: 'E2_HIGHCPU_8'
timeout: '600s'
EOF

# Construir imagen
gcloud builds submit --config=cloudbuild-api-gateway.yaml .
```

**Resultado:** BUILD SUCCESS en 3m13s

### 12.4 Configuraci√≥n de Kubernetes

#### Proxy-Client ConfigMap

```bash
cat > k8s/configmaps/proxy-client-config.yaml << 'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: proxy-client-config
  namespace: dev
data:
  SPRING_PROFILES_ACTIVE: "dev"
  EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: "http://service-discovery:8761/eureka/"
  SPRING_CONFIG_IMPORT: "optional:configserver:http://cloud-config:9296"
EOF

kubectl apply -f k8s/configmaps/proxy-client-config.yaml
```

#### API Gateway ConfigMap

```bash
cat > k8s/configmaps/api-gateway-config.yaml << 'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: api-gateway-config
  namespace: dev
data:
  SPRING_PROFILES_ACTIVE: "dev"
  EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: "http://service-discovery:8761/eureka/"
  SPRING_CONFIG_IMPORT: "optional:configserver:http://cloud-config:9296"
EOF

kubectl apply -f k8s/configmaps/api-gateway-config.yaml
```

### 12.5 Deployments

#### Proxy-Client Deployment

```bash
cat > k8s/deployments/proxy-client.yaml << 'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: proxy-client
  namespace: dev
spec:
  replicas: 1
  selector:
    matchLabels:
      app: proxy-client
  template:
    metadata:
      labels:
        app: proxy-client
    spec:
      initContainers:
      - name: wait-for-eureka
        image: busybox:1.36
        command: ['sh', '-c', 'until wget -qO- http://service-discovery:8761/actuator/health 2>/dev/null; do echo "Waiting for Eureka..."; sleep 3; done']
      containers:
      - name: proxy-client
        image: gcr.io/PROJECT_ID/proxy-client:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8900
        envFrom:
        - configMapRef:
            name: proxy-client-config
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /app/actuator/health/liveness
            port: 8900
          initialDelaySeconds: 120
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /app/actuator/health/readiness
            port: 8900
          initialDelaySeconds: 90
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: proxy-client
  namespace: dev
spec:
  type: ClusterIP
  selector:
    app: proxy-client
  ports:
  - port: 8900
    targetPort: 8900
    protocol: TCP
EOF

# Desplegar
PROJECT_ID=$(gcloud config get-value project)
sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/proxy-client.yaml | kubectl apply -f -
```

**Nota importante:** Los health checks incluyen el contexto `/app` porque la aplicaci√≥n lo requiere.

#### API Gateway Deployment con LoadBalancer

```bash
cat > k8s/deployments/api-gateway.yaml << 'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  namespace: dev
spec:
  replicas: 1
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      initContainers:
      - name: wait-for-eureka
        image: busybox:1.36
        command: ['sh', '-c', 'until wget -qO- http://service-discovery:8761/actuator/health 2>/dev/null; do echo "Waiting for Eureka..."; sleep 3; done']
      containers:
      - name: api-gateway
        image: gcr.io/PROJECT_ID/api-gateway:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
        envFrom:
        - configMapRef:
            name: api-gateway-config
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          initialDelaySeconds: 120
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 90
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: api-gateway
  namespace: dev
spec:
  type: LoadBalancer
  selector:
    app: api-gateway
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
EOF

# Desplegar
PROJECT_ID=$(gcloud config get-value project)
sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/api-gateway.yaml | kubectl apply -f -
```

**Diferencia clave:** El servicio api-gateway usa `type: LoadBalancer` para obtener una IP p√∫blica externa.

### 12.6 Verificaci√≥n Final

```bash
# Verificar todos los pods
kubectl get pods -n dev

# Resultado esperado (11/11 servicios):
# NAME                                 READY   STATUS    RESTARTS   AGE
# api-gateway-96d8cd7df-kvglq          1/1     Running   0          4m
# cloud-config-6bf65c6667-k4kzx        1/1     Running   0          15h
# favourite-service-67bff5cc9c-pr46c   1/1     Running   0          3h
# order-service-59bcd5669f-wvws4       1/1     Running   0          11h
# payment-service-96f88d57b-rn9sn      1/1     Running   0          11h
# postgres-0                           1/1     Running   0          14h
# product-service-5b5b9c599c-zpzt8     1/1     Running   0          11h
# proxy-client-7486dc6984-rqgpz        1/1     Running   0          4h
# service-discovery-c5c669f7c-86dp4    1/1     Running   0          14h
# shipping-service-6f585f6556-wkc9w    1/1     Running   0          11h
# user-service-658947cdcd-n48zs        1/1     Running   0          12h

# Obtener IP externa del API Gateway
kubectl get svc -n dev api-gateway

# NAME          TYPE           CLUSTER-IP       EXTERNAL-IP    PORT(S)        AGE
# api-gateway   LoadBalancer   34.118.237.222   34.31.129.29   80:30471/TCP   4m

# Probar acceso externo
curl http://34.31.129.29/actuator/health
```

### 12.7 Tabla de Servicios Completa

| Servicio | Puerto | Tipo | IP Externa | Estado |
|----------|--------|------|------------|--------|
| service-discovery | 8761 | ClusterIP | - | ‚úÖ Running |
| cloud-config | 9296 | ClusterIP | - | ‚úÖ Running |
| postgres | 5432 | ClusterIP | - | ‚úÖ Running |
| user-service | 8100 | ClusterIP | - | ‚úÖ Running |
| product-service | 8500 | ClusterIP | - | ‚úÖ Running |
| order-service | 8300 | ClusterIP | - | ‚úÖ Running |
| payment-service | 8400 | ClusterIP | - | ‚úÖ Running |
| shipping-service | 8600 | ClusterIP | - | ‚úÖ Running |
| favourite-service | 8800 | ClusterIP | - | ‚úÖ Running |
| proxy-client | 8900 | ClusterIP | - | ‚úÖ Running |
| api-gateway | 8080 | LoadBalancer | 34.31.129.29 | ‚úÖ Running |

### 12.8 Troubleshooting Espec√≠fico

#### Pod en Pending por CPU

```bash
# S√≠ntoma
kubectl get pods -n dev
# proxy-client-xxxxx   0/1     Pending   0          5m

# Diagn√≥stico
kubectl describe pod -n dev proxy-client-xxxxx
# Events: 0/5 nodes are available: 5 Insufficient cpu

# Soluci√≥n
gcloud container clusters update ecommerce-cluster \
    --zone=us-central1-a \
    --max-nodes=8

# Verificar autoscaling
kubectl get nodes -w
```

#### Health Checks con 404

```bash
# S√≠ntoma
kubectl describe pod -n dev proxy-client-xxxxx
# Events: Liveness probe failed: HTTP probe failed with statuscode: 404

# Diagn√≥stico - verificar contexto de la aplicaci√≥n
kubectl logs -n dev proxy-client-xxxxx | grep "Tomcat initialized"
# Tomcat initialized with port(s): 8900 (http)
# Initializing Spring embedded WebApplicationContext
# Root WebApplicationContext: initialization at [/app]

# Soluci√≥n - actualizar path del health check
# Cambiar /actuator/health ‚Üí /app/actuator/health
```

#### Pod Duplicado con InvalidImageName

```bash
# S√≠ntoma
kubectl get pods -n dev
# favourite-service-8dfbcb68-24rsm    1/1     Running          0          50m
# favourite-service-99766fdcc-b8fjj   0/1     InvalidImageName 0          10m

# Diagn√≥stico
kubectl describe pod -n dev favourite-service-99766fdcc-b8fjj | grep Image
# Image: gcr.io/PROJECT_ID/favourite-service:latest  # ‚ùå Literal

# Soluci√≥n
export PROJECT_ID=$(gcloud config get-value project)
sed "s/PROJECT_ID/$PROJECT_ID/g" k8s/deployments/favourite-service.yaml | kubectl apply -f -
kubectl delete pod -n dev favourite-service-99766fdcc-b8fjj
```

### 12.9 Restauraci√≥n de Recursos

Despu√©s de escalar el cl√∫ster, se pueden restaurar los recursos de favourite-service:

```yaml
# k8s/deployments/favourite-service.yaml
resources:
  requests:
    memory: "512Mi"    # Aumentado de 256Mi
    cpu: "250m"        # Aumentado de 100m
  limits:
    memory: "1Gi"
    cpu: "500m"

# Ajustar startup probe para tiempo reducido
startupProbe:
  httpGet:
    path: /actuator/health/liveness
    port: 8800
  initialDelaySeconds: 60
  periodSeconds: 10
  failureThreshold: 30  # Reducido de 50 (tiempo esperado ~120s vs 337s)
```

---

## 13. Pr√≥ximos Pasos

1. ‚úÖ Desplegar servicios de negocio (product, order, payment, shipping, favourite)
2. ‚úÖ Desplegar proxy-client con health checks corregidos
3. ‚úÖ Desplegar API Gateway con LoadBalancer y acceso externo
4. ‚úÖ Escalar cl√∫ster para recursos adecuados (max-nodes: 5‚Üí8)
5. Implementar Network Policies
6. Configurar Ingress Controller
7. Implementar Prometheus + Grafana para monitoreo
8. Configurar CI/CD con GitHub Actions
9. Implementar Horizontal Pod Autoscaler

---

## Variables de Entorno Importantes

```bash
# Guardar en ~/.zshrc o ~/.bashrc
export PROJECT_ID=$(gcloud config get-value project)
export CLUSTER_NAME="ecommerce-cluster"
export CLUSTER_ZONE="us-central1-a"
```

---

## Referencias

- [Google Kubernetes Engine Docs](https://cloud.google.com/kubernetes-engine/docs)
- [Kubectl Cheat Sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/)
- [Spring Boot with PostgreSQL](https://www.baeldung.com/spring-boot-postgresql-docker)
- [Flyway Database Migrations](https://flywaydb.org/documentation/)

---

**√öltima actualizaci√≥n:** 24 de noviembre de 2025
**Versi√≥n:** 2.1
**Estado:** ‚úÖ Despliegue completo (11/11 microservicios)

---

## Actualizaci√≥n de Versi√≥n

**v2.1 - 24 de noviembre de 2025:**
- ‚úÖ Secci√≥n 12 agregada: Despliegue de proxy-client y api-gateway
- ‚úÖ Documentaci√≥n de escalado del cl√∫ster (max-nodes: 5‚Üí8)
- ‚úÖ Soluci√≥n a health checks con contexto /app
- ‚úÖ Correcci√≥n de pods duplicados por InvalidImageName
- ‚úÖ Configuraci√≥n de LoadBalancer para acceso externo
- ‚úÖ Sistema completo: 11/11 microservicios desplegados

**v2.0 - 24 de noviembre de 2025:**
- ‚úÖ Secci√≥n 11 agregada: Despliegue automatizado de microservicios de negocio
- ‚úÖ Documentaci√≥n de troubleshooting para CrashLoopBackOff
- ‚úÖ Configuraci√≥n de startupProbe para aplicaciones de arranque lento
- ‚úÖ Script de despliegue automatizado (build-and-deploy-all.sh)
- ‚úÖ 9 microservicios desplegados y verificados en GKE
- ‚úÖ Resoluci√≥n de problemas de recursos (CPU/Memory) en el cl√∫ster
