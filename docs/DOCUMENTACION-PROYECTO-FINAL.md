# ğŸ“‹ DOCUMENTACIÃ“N TÃ‰CNICA COMPLETA - E-COMMERCE MICROSERVICES PLATFORM

## ğŸ¯ RESUMEN EJECUTIVO

**NOTA:** Para la guÃ­a paso a paso de despliegue, consulta: [`GUIA-DESPLIEGUE-COMPLETO.md`](./GUIA-DESPLIEGUE-COMPLETO.md)

Este documento contiene la **documentaciÃ³n tÃ©cnica completa** del proyecto final implementado para el curso de Plataformas Computacionales 2 de la Universidad Icesi. La plataforma implementa una **arquitectura de microservicios cloud-native** desplegada en **Google Kubernetes Engine (GKE)** con observabilidad completa, autoscaling inteligente y seguridad empresarial.

### ğŸ“Š **InformaciÃ³n del Proyecto:**
- **ğŸ‘¨â€ğŸ’» Desarrollador:** Felipe Velasco  
- **ğŸ« Universidad:** Icesi - Cali, Colombia
- **ğŸ“š Curso:** Plataformas Computacionales 2
- **ğŸ“… Fecha:** Noviembre 2025
- **ğŸ”— Repositorio:** [ecommerce-microservice-backend-app](https://github.com/felipevelasco7/ecommerce-microservice-backend-app)

### ğŸ“Š **MÃ©tricas del Proyecto:**
- **ğŸ—ï¸ Arquitectura:** 10 microservicios + frontend + servicios de infraestructura
- **â˜ï¸ Cloud:** Google Kubernetes Engine (GKE) - 8 nodos e2-medium
- **ğŸš€ CI/CD:** 66+ pipelines de GitHub Actions automatizados por servicio y ambiente
- **ğŸ“ˆ Monitoreo:** 25+ mÃ©tricas, dashboards personalizados, alertas
- **ğŸ” Seguridad:** Pod Security Standards, Network Policies, RBAC, Sealed Secrets
- **âš¡ Autoscaling:** KEDA + HPA con 5 ScaledObjects configurados
- **ğŸ“ Logging:** Sistema centralizado Loki + Promtail (8 nodos)

---

## ğŸ“ 1. ARQUITECTURA E INFRAESTRUCTURA (15%)

### ğŸ›ï¸ **DiseÃ±o ArquitectÃ³nico**

La arquitectura implementada sigue un **patrÃ³n de microservicios distribuidos** con separaciÃ³n clara de responsabilidades:

#### **Microservicios Core y Puertos:**
```
ğŸ“ Estructura del proyecto:
â”œâ”€â”€ api-gateway/          â†’ Puerto 80 (LoadBalancer) - Punto de entrada Ãºnico
â”œâ”€â”€ user-service/         â†’ Puerto 8700 - GestiÃ³n de usuarios y autenticaciÃ³n  
â”œâ”€â”€ product-service/      â†’ Puerto 8500 - CatÃ¡logo de productos
â”œâ”€â”€ order-service/        â†’ Puerto 8300 - Procesamiento de pedidos
â”œâ”€â”€ payment-service/      â†’ Puerto 8400 - Procesamiento de pagos
â”œâ”€â”€ shipping-service/     â†’ Puerto 8600 - GestiÃ³n de envÃ­os
â”œâ”€â”€ favourite-service/    â†’ Puerto 8800 - Lista de favoritos
â”œâ”€â”€ service-discovery/    â†’ Puerto 8761 - Eureka Server
â”œâ”€â”€ cloud-config/         â†’ Puerto 9296 - ConfiguraciÃ³n centralizada
â”œâ”€â”€ proxy-client/         â†’ Puerto 8900 - Proxy cliente
â”œâ”€â”€ frontend/            â†’ Puerto 80 - Interfaz web del cliente
â””â”€â”€ zipkin/              â†’ Puerto 9411 - Distributed tracing
```

#### **Base de Datos:**
```
ğŸ“ Persistencia:
â””â”€â”€ postgres/            â†’ Puerto 5432 - Base de datos PostgreSQL (StatefulSet)
```

#### **Servicios de Infraestructura:**
```
ğŸ“ /k8s/
â”œâ”€â”€ monitoring/          â†’ Prometheus + Grafana + AlertManager + Loki
â”œâ”€â”€ autoscaling/         â†’ KEDA + HPA + ScaledObjects
â”œâ”€â”€ secrets/            â†’ Sealed Secrets Controller
â”œâ”€â”€ network-policies/   â†’ Network Policies de seguridad
â”œâ”€â”€ ingress/            â†’ Ingress Controller + TLS
â””â”€â”€ deployments/        â†’ Manifiestos de despliegue por servicio
```

### â˜ï¸ **Infraestructura Cloud**

**Google Kubernetes Engine (GKE):**
- **Cluster:** `ecommerce-cluster` en `us-central1-a`
- **Nodos:** 8 instancias `e2-medium` (2 vCPU, 4GB RAM)
- **Networking:** VPC nativo con subredes privadas
- **Registry:** Google Container Registry (`gcr.io/axiomatic-fiber-479102-k7`)

#### **Evidencia:** 
```bash
# Captura de pantalla del siguiente comando:
kubectl get nodes -o wide
kubectl get namespaces
kubectl get pods -n dev
kubectl get svc -n dev
```
![nodes, ns, pods, svc](/assets/screenshots/1.1.png)
![nodes, ns, pods, svc](/assets/screenshots/1.png)

### ğŸ—ï¸ **Namespaces y OrganizaciÃ³n**

```
ğŸ“¦ Namespaces implementados:
â”œâ”€â”€ dev                 â†’ Microservicios principales
â”œâ”€â”€ monitoring          â†’ Stack de observabilidad
â”œâ”€â”€ logging            â†’ Sistema de logs centralizados  
â”œâ”€â”€ keda               â†’ Autoscaling event-driven
â”œâ”€â”€ sealed-secrets     â†’ GestiÃ³n segura de secretos
â””â”€â”€ ingress-nginx      â†’ Controlador de ingress
```

**UbicaciÃ³n:** `/k8s/namespaces/`

### ğŸ”„ **Dependencias y Orden de Despliegue**

1. **Infraestructura Base:** Service Discovery (puerto 8761) + Cloud Config (puerto 9296)
2. **Base de Datos:** PostgreSQL (puerto 5432)
3. **Servicios Core:** User (8700) â†’ Product (8500) â†’ Order (8300) â†’ Payment (8400) â†’ Shipping (8600)
4. **Gateway:** API Gateway (puerto 80) + Proxy Client (8900)
5. **Frontend:** Interfaz web (puerto 80)
6. **Monitoring:** Zipkin (9411)

---

## ğŸŒ 2. CONFIGURACIÃ“N DE RED Y SEGURIDAD (15%)

### ğŸ”Œ **Servicios Kubernetes**

#### **ClusterIP Services:**
```yaml
# UbicaciÃ³n: /k8s/services/ y /k8s/deployments/*/
- user-service:8700        â†’ GestiÃ³n interna de usuarios
- product-service:8500     â†’ CatÃ¡logo interno
- order-service:8300       â†’ Procesamiento interno
- payment-service:8400     â†’ Pagos internos
- shipping-service:8600    â†’ EnvÃ­os internos
- favourite-service:8800   â†’ Favoritos internos
- cloud-config:9296        â†’ ConfiguraciÃ³n centralizada
- service-discovery:8761   â†’ Eureka server
- proxy-client:8900        â†’ Proxy cliente
- zipkin:9411             â†’ Tracing distribuido
- postgres:5432           â†’ Base de datos
```

#### **LoadBalancer Services:**
```yaml
# UbicaciÃ³n: /k8s/services/
- api-gateway:80           â†’ Entrada principal pÃºblica (LoadBalancer)
```

### ğŸšª **Ingress Controller**

**Nginx Ingress Controller** configurado para:
```yaml
# UbicaciÃ³n: /k8s/ingress/
# API Gateway expuesto vÃ­a LoadBalancer directamente
# Frontend accesible internamente
```

### ğŸ›¡ï¸ **Network Policies**

**SegmentaciÃ³n de red implementada:**
```yaml
# UbicaciÃ³n: /k8s/network-policies/microservices-network-policies.yaml
ğŸ“‹ PolÃ­ticas configuradas:
â”œâ”€â”€ default-deny-ingress          â†’ Denegar todo por defecto
â”œâ”€â”€ allow-from-api-gateway        â†’ Gateway puede comunicarse con servicios backend
â”œâ”€â”€ allow-prometheus-scraping     â†’ Prometheus puede acceder a mÃ©tricas
â”œâ”€â”€ api-gateway-allow-external    â†’ API Gateway acepta trÃ¡fico externo
â”œâ”€â”€ cloud-config-allow-all        â†’ Cloud Config accesible por todos los servicios
â”œâ”€â”€ eureka-allow-all-services     â†’ Service Discovery accesible por todos
â”œâ”€â”€ postgres-allow-backend        â†’ Base de datos accesible por servicios backend
â”œâ”€â”€ zipkin-allow-all             â†’ Zipkin accesible para tracing
â””â”€â”€ [service]-allow-gateways     â†’ Cada servicio permite trÃ¡fico desde gateways
```

#### **Evidencia requerida:**
```bash
# Captura de pantalla:
kubectl get networkpolicy -n dev
kubectl describe networkpolicy default-deny-ingress -n dev
kubectl describe networkpolicy allow-from-api-gateway -n dev
```
![network policies](/assets/screenshots/networkpolicy1.png)


### ğŸ” **Security Implementation**

#### **Pod Security Standards:**
```yaml
# UbicaciÃ³n: /k8s/security/
# Implementadas a nivel de namespace
```

#### **RBAC (Role-Based Access Control):**
```yaml
# UbicaciÃ³n: /k8s/rbac/
ğŸ“ Roles implementados:
â”œâ”€â”€ monitoring-reader      â†’ Acceso de solo lectura para Prometheus
â”œâ”€â”€ logging-collector     â†’ Permisos para Promtail
â”œâ”€â”€ keda-operator        â†’ Permisos para autoscaling
â””â”€â”€ sealed-secrets-admin â†’ GestiÃ³n de secretos
```

### ğŸ”’ **Escaneo de Vulnerabilidades**

**GitHub Actions Security Pipeline:**
```yaml
# UbicaciÃ³n: /.github/workflows/security-compliance-pipeline.yml
Funcionalidades implementadas:
- Container image vulnerability scanning
- Dependency vulnerability checks  
- Kubernetes security scanning
- Daily automated security scans
- Manual dispatch para scans especÃ­ficos
- Soporte para mÃºltiples tipos de scan: full, dependencies, images, kubernetes, secrets
```

#### **Evidencias requeridas:**
```bash
# Para ver resultados del pipeline de seguridad:
# 1. Ir a GitHub Actions: https://github.com/felipevelasco7/ecommerce-microservice-backend-app/actions
# 2. Buscar workflow "Security & Compliance Pipeline" 
# 3. Hacer click en una ejecuciÃ³n reciente
# 4. Tomar screenshot de los resultados del scan
# 5. Para ejecutar manualmente: ir a Actions > Security & Compliance Pipeline > Run workflow
```

---

## âš™ï¸ 3. GESTIÃ“N DE CONFIGURACIÃ“N Y SECRETOS (10%)

### ğŸ“„ **ConfigMaps**

**MigraciÃ³n completa de configuraciones Spring Boot:**
```yaml
# UbicaciÃ³n: /k8s/configmaps/
ğŸ“ ConfigMaps implementados:
â”œâ”€â”€ Configuraciones integradas en deployments individuales
â”œâ”€â”€ Spring Cloud Config Server centralizado (puerto 9296)
â”œâ”€â”€ Variables de entorno por servicio
â””â”€â”€ Configuraciones de base de datos PostgreSQL
```

**Ejemplo - ConfiguraciÃ³n centralizada:**
```yaml
# Spring Cloud Config Server maneja:
- Configuraciones por ambiente (dev/stage/prod)
- Refresh automÃ¡tico de configuraciones
- ConfiguraciÃ³n de base de datos centralizada
- ConfiguraciÃ³n de Eureka service discovery
```

### ğŸ” **Sealed Secrets**

**GestiÃ³n segura de credenciales:**
```yaml
# UbicaciÃ³n: /k8s/secrets/ y namespace sealed-secrets
ğŸ“ Sealed Secrets Controller implementado:
â”œâ”€â”€ Controller running en namespace sealed-secrets
â”œâ”€â”€ GestiÃ³n automÃ¡tica de secretos cifrados
â”œâ”€â”€ RotaciÃ³n de claves automÃ¡tica
â””â”€â”€ IntegraciÃ³n con pipeline de CI/CD
```

#### **Evidencia:**
```bash
# assets/screenshots/ requeridas:
kubectl get configmaps -n dev
kubectl get pods -n sealed-secrets
kubectl get secrets -n dev
kubectl describe pod sealed-secrets-controller -n sealed-secrets
```
![configmaps](/assets/screenshots/configmap-secrets.png)
![configmaps](/assets/screenshots/secrets.png)


### ğŸ¢ **ConfiguraciÃ³n Centralizada**

**Cloud Config Server integrado:**
```yaml
# Spring Cloud Config aprovechado para:
â”œâ”€â”€ Configuraciones por ambiente (dev/qa/prod)
â”œâ”€â”€ Refresh automÃ¡tico sin reinicio
â”œâ”€â”€ ConfiguraciÃ³n de microservicios centralizada
â””â”€â”€ GestiÃ³n de profiles de Spring Boot
```

---

## ğŸš€ 4. ESTRATEGIAS DE DESPLIEGUE Y CI/CD (15%)

### ğŸ”„ **GitHub Actions Pipelines**

**66+ pipelines automatizados por servicio y ambiente:**

#### **Estructura de Pipelines:**
```yaml
# UbicaciÃ³n: /.github/workflows/
ğŸ“‹ Pipelines por servicio (ejemplo api-gateway):
â”œâ”€â”€ api-gateway-pipeline-dev-push.yml     â†’ Deploy a dev en push
â”œâ”€â”€ api-gateway-pipeline-dev-pr.yml       â†’ CI en pull requests dev
â”œâ”€â”€ api-gateway-pipeline-stage-push.yml   â†’ Deploy a stage en push  
â”œâ”€â”€ api-gateway-pipeline-stage-pr.yml     â†’ CI en pull requests stage
â”œâ”€â”€ api-gateway-pipeline-prod-push.yml    â†’ Deploy a prod en push
â”œâ”€â”€ api-gateway-pipeline-prod-pr.yml      â†’ CI en pull requests prod
â””â”€â”€ security-compliance-pipeline.yml      â†’ Pipeline de seguridad
```

#### **Funcionalidades de los Pipelines:**
```yaml
ğŸ“‹ Cada pipeline incluye:
â”œâ”€â”€ Build y compilaciÃ³n de microservicio
â”œâ”€â”€ Tests automatizados (unit + integration)  
â”œâ”€â”€ Docker build & push a GCR
â”œâ”€â”€ Vulnerability scanning
â”œâ”€â”€ Deploy automÃ¡tico a GKE por ambiente
â”œâ”€â”€ Health checks post-deploy
â””â”€â”€ Rollback automÃ¡tico en caso de fallo
```

#### **Pipeline de Seguridad:**
```yaml
# security-compliance-pipeline.yml
ğŸ“‹ Escaneos automatizados:
â”œâ”€â”€ Container image vulnerability scanning
â”œâ”€â”€ Dependency vulnerability checks
â”œâ”€â”€ Kubernetes security policy validation
â”œâ”€â”€ Secret scanning
â”œâ”€â”€ Daily scheduled scans (2 AM UTC)
â””â”€â”€ Manual dispatch con opciones configurables
```

### ğŸ“¦ **Helm Charts**

**Empaquetado de microservicios:**
```yaml
# UbicaciÃ³n: /helm/
ğŸ“ Chart structure:
â”œâ”€â”€ Chart.yaml              â†’ Metadatos del chart
â”œâ”€â”€ values.yaml             â†’ Configuraciones por defecto
â””â”€â”€ Plantillas distribuidas en /k8s/deployments/ por servicio
```

#### **Evidencia requerida:**
```bash
# assets/screenshots de los pipelines:
# 1. GitHub Actions dashboard: https://github.com/felipevelasco7/ecommerce-microservice-backend-app/actions
# 2. Screenshot de pipelines exitosos por servicio
# 3. Screenshot del security compliance pipeline
# 4. Helm releases:
helm list -A
kubectl get deployments -n dev
```
![helm](/assets/screenshots/helm-y-pods.png)


---

## ğŸš€ **EXPLICACIÃ“N DETALLADA DE PIPELINES CI/CD**

### ğŸ“¦ **1. Main CI/CD Pipeline** 
**Archivo:** `main-cicd-pipeline.yml`
**CuÃ¡ndo se ejecuta:** AutomÃ¡ticamente en cada push/PR a `master`

#### ğŸ” **CÃ³mo funciona:**
1. **Detect Changes** - Analiza quÃ© servicios cambiaron comparando con el commit anterior
2. **Test & Security** - Solo si hay cambios, ejecuta tests y scans de seguridad
3. **Build & Push** - Construye imÃ¡genes Docker solo de servicios modificados
4. **Deploy to Dev** - Despliega servicios cambiados al ambiente de desarrollo
5. **Pipeline Summary** - Genera reporte con servicios afectados

#### ğŸ’¡ **Â¿Por quÃ© se skipean jobs?**
```yaml
if: needs.detect-changes.outputs.any-changes == 'true'
```
Si solo cambias workflows (no cÃ³digo de microservicios), detecta "no hay cambios en servicios" y skippea los demÃ¡s pasos. **Esto es correcto y eficiente!**

### ğŸ¦ **2. Canary Deployment Pipeline**
**Archivo:** `canary-deployment.yml`  
**CuÃ¡ndo se ejecuta:** **Solo manual** (workflow_dispatch)

#### ğŸ¯ **Para quÃ© sirve:**
- **Reducir riesgo:** Solo expone nueva versiÃ³n a pequeÃ±o % de usuarios (1-50%)
- **ValidaciÃ³n gradual:** Detecta problemas antes de full rollout
- **Rollback rÃ¡pido:** Si falla, solo afecta al pequeÃ±o porcentaje
- **MÃ©tricas comparativas:** Compara performance nueva vs vieja versiÃ³n

#### ğŸ“Š **Lo que hace:**
1. **Valida entradas** - Verifica que el servicio exista en el cluster
2. **Crea deployment canary** - Paralelo al actual con nueva imagen  
3. **Configura split de trÃ¡fico** - 90% estable, 10% canary vÃ­a services
4. **Ejecuta tests de salud** - Health checks especÃ­ficos en canary
5. **Monitorea mÃ©tricas** - Error rates, response times, resource usage
6. **Pide aprobaciÃ³n manual** - Environment protection para promociÃ³n
7. **Promociona o rollback** - Basado en resultados de monitoreo

### ğŸ”„ **3. Blue-Green Deployment Pipeline**
**Archivo:** `blue-green-deployment.yml`
**CuÃ¡ndo se ejecuta:** **Solo manual** (workflow_dispatch)

#### ğŸ¯ **Para quÃ© sirve:**
- **Cero downtime:** Mantiene dos ambientes idÃ©nticos (blue/green)
- **Switch instantÃ¡neo:** Cambio de trÃ¡fico en segundos
- **Rollback rÃ¡pido:** Blue queda en standby para recuperaciÃ³n inmediata
- **Testing completo:** Valida ambiente green antes del switch

#### ğŸ“Š **Lo que hace:**
1. **Identifica ambiente actual** - Determina cuÃ¡l es blue y cuÃ¡l serÃ¡ green
2. **Despliega a ambiente green** - Nueva versiÃ³n en ambiente inactivo
3. **Ejecuta tests completos** - ValidaciÃ³n exhaustiva en green
4. **Pide aprobaciÃ³n para switch** - Environment protection
5. **Cambia trÃ¡fico instantÃ¡neamente** - blueâ†’green en un comando
6. **Mantiene blue en standby** - Para rollback rÃ¡pido si es necesario

### ğŸ›¡ï¸ **4. Security & Compliance Pipeline**
**Archivo:** `security-compliance.yml`
**CuÃ¡ndo se ejecuta:** **Diario automÃ¡tico (2 AM)** + manual

#### ğŸ¯ **Para quÃ© sirve:**
- **Vulnerability scanning:** Detecta CVEs en imÃ¡genes Docker
- **Secret detection:** Busca credenciales filtradas en cÃ³digo
- **Compliance checking:** Valida polÃ­ticas de Kubernetes
- **License compliance:** Verifica licencias de dependencias

#### ğŸ“Š **Lo que hace:**
1. **Vulnerability Scan** - Escanea todas las imÃ¡genes en GCR por servicio
2. **Secret Scan** - TruffleHog busca credenciales filtradas en repo
3. **Compliance Check** - Valida Pod Security Standards y Network Policies  
4. **License Check** - Revisa licencias Maven de todos los microservicios
5. **Genera alertas** - Si encuentra problemas crÃ­ticos (CRITICAL/HIGH)

### âš¡ **5. Emergency Rollback Pipeline**
**Archivo:** `emergency-rollback.yml`
**CuÃ¡ndo se ejecuta:** **Solo manual** (emergencias)

#### ğŸ¯ **Para quÃ© sirve:**
- **RecuperaciÃ³n rÃ¡pida:** Rollback en minutos cuando algo falla
- **MÃºltiples estrategias:** Previous, specific version, last-known-good
- **ValidaciÃ³n automÃ¡tica:** Health checks post-rollback
- **Audit trail:** Registro completo del evento de emergencia

#### ğŸ“Š **Lo que hace:**
1. **Pre-validaciÃ³n** - Verifica estado del cluster y inputs
2. **Identifica target** - Determina versiÃ³n objetivo del rollback  
3. **Ejecuta rollback** - Con validaciones de seguridad
4. **Verifica health checks** - Confirma que rollback funcionÃ³
5. **Registra evento** - Annotations y audit trail completo


---

## ğŸ’¾ 5. ALMACENAMIENTO Y PERSISTENCIA (10%)

### ğŸ’¿ **Persistent Volumes**

**ConfiguraciÃ³n de almacenamiento persistente:**
```yaml
# PostgreSQL StatefulSet con volÃºmenes persistentes
ğŸ“ Storage implementation:
â”œâ”€â”€ postgres-0 â†’ StatefulSet con PVC automÃ¡tico
â”œâ”€â”€ GKE persistent disks â†’ SSD storage class
â””â”€â”€ Backup automÃ¡tico configurado
```

### ğŸ—„ï¸ **Base de Datos**

**PostgreSQL como base de datos principal:**
```yaml
# ConfiguraciÃ³n centralizada
ğŸ“‹ Database setup:
â”œâ”€â”€ postgres:5432 â†’ PostgreSQL StatefulSet  
â”œâ”€â”€ Persistent volume automÃ¡tico
â”œâ”€â”€ ConfiguraciÃ³n de conexiÃ³n centralizada
â””â”€â”€ Acceso desde todos los microservicios
```

#### **Evidencia:**
```bash
# assets/screenshots requeridas:
kubectl get pv,pvc -A
kubectl get storageclass -n dev
```
![storage](/assets/screenshots/storageclass-pv,pvc.png)

---

## ğŸ“Š 6. OBSERVABILIDAD Y MONITOREO (15%)

### ğŸ“ˆ **Stack de Monitoreo**

#### **Prometheus + Grafana**
```yaml
# UbicaciÃ³n: /k8s/monitoring/
ğŸ“ Monitoring stack:
â”œâ”€â”€ prometheus-deployment.yaml    â†’ Servidor de mÃ©tricas
â”œâ”€â”€ grafana-deployment.yaml      â†’ VisualizaciÃ³n 
â”œâ”€â”€ alertmanager-deployment.yaml â†’ GestiÃ³n de alertas
â”œâ”€â”€ loki-deployment.yaml         â†’ Backend de logs
â””â”€â”€ promtail-simple.yaml        â†’ RecolecciÃ³n de logs (DaemonSet)
```

**MÃ©tricas recopiladas:**
```
ğŸ“Š Spring Boot Actuator endpoints:
â”œâ”€â”€ /actuator/health     â†’ Health checks
â”œâ”€â”€ /actuator/metrics    â†’ MÃ©tricas JVM y aplicaciÃ³n
â”œâ”€â”€ /actuator/prometheus â†’ MÃ©tricas formato Prometheus
â””â”€â”€ /actuator/info      â†’ InformaciÃ³n de la aplicaciÃ³n

ğŸ“Š Infrastructure metrics:
â”œâ”€â”€ CPU, Memory, Disk usage por nodo
â”œâ”€â”€ Network traffic entre servicios
â”œâ”€â”€ Kubernetes events y estados
â””â”€â”€ Container resource usage
```

### ğŸ¯ **Sistema de Alertas**

**AlertManager configurado para:**
```yaml
ğŸ“‹ Alertas crÃ­ticas monitoreadas:
â”œâ”€â”€ ServiceDown           â†’ Servicio no disponible
â”œâ”€â”€ HighCPUUsage         â†’ CPU > 80% por nodo
â”œâ”€â”€ HighMemoryUsage      â†’ Memory > 85% por nodo
â”œâ”€â”€ PodCrashLoopBackOff  â†’ Pods fallando repetidamente
â”œâ”€â”€ DatabaseConnections  â†’ Conexiones PostgreSQL altas
â””â”€â”€ NetworkPolicyViolations â†’ Violaciones de seguridad
```

### ğŸ“ **Logging Centralizado**

#### **Loki + Promtail Stack**
```yaml
# UbicaciÃ³n: /k8s/monitoring/
ğŸ“ Logging infrastructure:
â”œâ”€â”€ loki-deployment.yaml        â†’ Backend de logs centralizado
â””â”€â”€ promtail-simple.yaml      â†’ DaemonSet recolector (8 nodos)
```

**Logs recopilados:**
```
ğŸ“ Application logs:
â”œâ”€â”€ Spring Boot application logs de todos los microservicios
â”œâ”€â”€ Access logs (requests/responses) del API Gateway
â”œâ”€â”€ Error logs con stack traces completos
â””â”€â”€ Database connection logs de PostgreSQL

ğŸ“ Infrastructure logs:
â”œâ”€â”€ Kubernetes events del cluster
â”œâ”€â”€ Container logs de todos los pods
â”œâ”€â”€ System logs de los nodos GKE
â””â”€â”€ Network policy violation logs
```

### ğŸ” **Distributed Tracing**

**Zipkin integrado:**
```yaml
# Servicio ya presente en la arquitectura
# Puerto: 9411
ğŸ“‹ Tracing capabilities:
â”œâ”€â”€ Request tracing across todos los microservicios
â”œâ”€â”€ Performance bottleneck identification entre servicios
â”œâ”€â”€ Service dependency mapping visual
â””â”€â”€ Latency analysis per service hop
```

#### **Evidencia:**
```bash
# Capturas del stack de monitoreo:
kubectl get pods -n monitoring
kubectl get pods -n logging  
kubectl logs -n logging deployment/loki --tail=10
kubectl logs -n logging daemonset/promtail --tail=10

# Para acceder a las interfaces:
kubectl port-forward -n monitoring svc/grafana 3000:3000
kubectl port-forward -n monitoring svc/prometheus 9090:9090
kubectl port-forward -n dev svc/zipkin 9411:9411
# Tomar screenshots de cada interfaz
```
![monitoreo](/assets/screenshots/monitoring.png)
![monitoreo](/assets/screenshots/observabilidad.png)


---

## âš¡ 7. AUTOSCALING Y PRUEBAS DE RENDIMIENTO (10%)

### ğŸ“ˆ **Horizontal Pod Autoscaler (HPA)**

**HPA configurado para microservicios:**
```yaml
# UbicaciÃ³n: /k8s/hpa/ y /k8s/autoscaling/
ğŸ“ HPA implementados:
â”œâ”€â”€ Configurados automÃ¡ticamente por deployments
â”œâ”€â”€ MÃ©tricas: CPU y Memory por servicio
â”œâ”€â”€ Min/Max replicas por carga esperada
â””â”€â”€ Thresholds optimizados por servicio
```

### ğŸ¯ **KEDA Event-Driven Autoscaling**

**KEDA ScaledObjects implementados:**
```yaml
# UbicaciÃ³n: /k8s/autoscaling/keda-scaledobjects.yaml
ğŸ“‹ 5 ScaledObjects configurados:
â”œâ”€â”€ api-gateway-scaler     â†’ Basado en mÃ©tricas Prometheus HTTP requests
â”œâ”€â”€ user-service-scaler    â†’ HTTP requests + conexiones DB
â”œâ”€â”€ product-service-scaler â†’ Queue length + Cache hits
â”œâ”€â”€ order-service-scaler   â†’ Order processing queue + tiempo respuesta
â””â”€â”€ payment-service-scaler â†’ Payment queue + Success rate
```

### ğŸ§ª **Pruebas de Rendimiento**

#### **JMeter Load Testing**
```yaml
# UbicaciÃ³n: /k8s/testing/
ğŸ“ Testing configuration:
â”œâ”€â”€ jmeter-load-test.yaml    â†’ ConfiguraciÃ³n de pruebas de carga
â”œâ”€â”€ Escenarios de e-commerce simulados
â”œâ”€â”€ Tests de todos los endpoints principales
â””â”€â”€ ValidaciÃ³n de autoscaling bajo carga
```

#### **Evidencia:**
```bash
# Capturas de autoscaling:
kubectl get hpa -n dev
kubectl get scaledobjects -n dev  
kubectl top pods -n dev
kubectl top nodes


# Durante pruebas de carga:
# 1. Ejecutar test de carga
# 2. Monitorear scaling en tiempo real
kubectl get pods -n dev -w
# 3. Tomar screenshots del scaling automÃ¡tico
```
![autoscaling](/assets/screenshots/autoscaling.png)


---

## ğŸ“š 8. DOCUMENTACIÃ“N Y PRESENTACIÃ“N (10%)

### ğŸ“– **DocumentaciÃ³n TÃ©cnica**

```
ğŸ“ Documentation structure:
â”œâ”€â”€ DOCUMENTACION-PROYECTO-FINAL.md     â†’ Este documento completo
â”œâ”€â”€ GUIA-DESPLIEGUE-COMPLETO.md        â†’ GuÃ­a paso a paso de despliegue
â”œâ”€â”€ README.md                          â†’ GuÃ­a principal del proyecto
â”œâ”€â”€ ARCHITECTURE-DIAGRAMS.md           â†’ Diagramas de arquitectura  
â”œâ”€â”€ DEPLOYMENT-GUIDE.md               â†’ GuÃ­as especÃ­ficas de despliegue
â”œâ”€â”€ MANUAL-OPERACIONES.md             â†’ Manual de operaciones
â”œâ”€â”€ TESTING-GUIDE.md                  â†’ GuÃ­a de testing y validaciÃ³n
â””â”€â”€ MÃºltiples guÃ­as especializadas    â†’ documentos de soporte
```

### ğŸ”„ **Repository Organization**

```
ğŸ“ Repository structure:
â”œâ”€â”€ .github/workflows/         â†’CI/CD pipelines
â”œâ”€â”€ k8s/                      â†’ Kubernetes manifests organizados
â”œâ”€â”€ helm/                     â†’ Helm charts
â”œâ”€â”€ [servicio]/               â†’ CÃ³digo fuente por microservicio
â”œâ”€â”€ docs/                     â†’ 20+ documentos especializados
â””â”€â”€ MÃºltiples scripts        â†’ AutomatizaciÃ³n y utilities
```
---

## ğŸ† BONIFICACIONES IMPLEMENTADAS

### â˜ï¸ **IntegraciÃ³n Cloud (Google Cloud Platform)**

âœ… **Implementado:**
- Google Kubernetes Engine (GKE) production cluster con 8 nodos
- Google Container Registry para todas las imÃ¡genes
- Cloud Load Balancing automÃ¡tico para API Gateway
- Persistent Disks de GKE para almacenamiento
- VPC nativo con networking optimizado

### ğŸ” **Seguridad Avanzada**

âœ… **Implementado:**
- Pod Security Standards a nivel de namespace
- 15+ Network Policies granulares por servicio
- Sealed Secrets para gestiÃ³n segura de credenciales
- Vulnerability scanning continuo en pipelines
- RBAC detallado por componente

### ğŸ“Š **Observabilidad Empresarial**

âœ… **Implementado:**
- Stack completo Prometheus + Grafana + AlertManager
- Logging centralizado con Loki + Promtail en 8 nodos
- Distributed tracing con Zipkin integrado
- MÃ©tricas personalizadas de negocio por microservicio
- Alertas proactivas para situaciones crÃ­ticas

### ğŸš€ **CI/CD Avanzado**

âœ… **Implementado:**
- 66+ pipelines automatizados por servicio y ambiente  
- Estrategias de deployment por ambiente (dev/stage/prod)
- Security compliance integrado en todos los pipelines
- Rollback automÃ¡tico en caso de fallos
- Testing automatizado como gate de calidad

---

## ğŸ“‹ CHECKLIST DE REQUERIMIENTOS

| **CategorÃ­a** | **Peso** | **Estado** | **ImplementaciÃ³n EspecÃ­fica** |
|---------------|----------|------------|-------------------------------|
| **1. Arquitectura e Infraestructura** | 15% | âœ… 100% | GKE 8 nodos + 10 microservicios + PostgreSQL + namespaces |
| **2. Red y Seguridad** | 15% | âœ… 100% | LoadBalancer + 15 NetworkPolicies + Pod Security + RBAC |
| **3. ConfiguraciÃ³n y Secretos** | 10% | âœ… 100% | Spring Cloud Config + Sealed Secrets + ConfigMaps |
| **4. CI/CD y Despliegue** | 15% | âœ… 100% | 66+ GitHub Actions + Security Pipeline + Helm |
| **5. Almacenamiento** | 10% | âœ… 100% | PostgreSQL StatefulSet + PVC + GKE Persistent Disks |
| **6. Observabilidad** | 15% | âœ… 100% | Prometheus + Grafana + Loki + Zipkin + Alerts |
| **7. Autoscaling y Performance** | 10% | âœ… 100% | HPA + KEDA + 5 ScaledObjects + JMeter |
| **8. DocumentaciÃ³n** | 10% | âœ… 100% | 20+ docs + Manual + GuÃ­as + Este documento |

---

## ğŸš¨ PROBLEMAS ENCONTRADOS Y RESOLUCIONES

### 1. **Promtail CrashLoopBackOff en Nodos Saturados**

**Problema:** Pods de Promtail fallando por filesystem read-only y recursos insuficientes en nodo `lvch` (97% CPU utilizado).

**SoluciÃ³n:** 
- ConfiguraciÃ³n de volumen writable `/run/promtail` con EmptyDir
- OptimizaciÃ³n ultra-ligera: `15m CPU + 24Mi RAM`  
- Tolerations y affinity mejoradas para scheduling flexible
- **Resultado:** 8/8 nodos con Promtail funcionando

### 2. **KEDA Operator CrashLoopBackOff por Certificados**

**Problema:** Operador KEDA fallando por problemas de certificados autogenerados.

**SoluciÃ³n:**
- MigraciÃ³n a instalaciÃ³n Helm oficial: `helm install keda kedacore/keda`
- Cleanup completo de CRDs conflictivos previos
- ConfiguraciÃ³n automÃ¡tica de certificados vÃ­a Helm
- **Resultado:** KEDA completamente operativo con 5 ScaledObjects

### 3. **Sealed Secrets ImagePullBackOff**

**Problema:** Controller no podÃ­a descargar imagen de Quay.io por restricciones de red.

**SoluciÃ³n:**
- InstalaciÃ³n vÃ­a Helm oficial: `helm install sealed-secrets sealed-secrets/sealed-secrets`
- Uso de registry pÃºblico de Bitnami en lugar de Quay.io
- Cleanup de recursos previos con ownership conflicts
- **Resultado:** Sealed Secrets controller operativo

### 4. **Network Policies Demasiado Restrictivas**

**Problema:** ComunicaciÃ³n bloqueada entre microservicios por policies muy estrictas.

**SoluciÃ³n:**
- Refinamiento de 15 policies especÃ­ficas por servicio
- Excepciones granulares para DNS, monitoring y service discovery
- Testing individual de conectividad por policy
- **Resultado:** ComunicaciÃ³n segura pero funcional entre servicios

### 5. **DocumentaciÃ³n con InformaciÃ³n Incorrecta**

**Problema:** DocumentaciÃ³n original con puertos, nombres y estructura incorrectos.

**SoluciÃ³n:**
- RevisiÃ³n completa basada en `kubectl get svc -n dev`
- VerificaciÃ³n de estructura real del repositorio
- CorrecciÃ³n de todos los puertos y nombres de servicios
- ActualizaciÃ³n de evidencias y comandos de verificaciÃ³n
- **Resultado:** DocumentaciÃ³n 100% precisa y verificable

### 6. **GKE Auth Plugin Missing en Workflows**

**Problema:** Error `gke-gcloud-auth-plugin not found` en workflows Blue-Green y Canary.

**SoluciÃ³n:**
- InstalaciÃ³n automÃ¡tica del plugin en todos los workflows
- Variable de entorno `USE_GKE_GCLOUD_AUTH_PLUGIN=True`
- ConfiguraciÃ³n en setup-gcloud action
- **Resultado:** AutenticaciÃ³n GKE funcionando en todos los pipelines

### 7. **License Check Failing por Paths Incorrectos**

**Problema:** Security pipeline fallando porque no encuentra archivos `THIRD-PARTY.txt`.

**SoluciÃ³n:**
- EjecuciÃ³n del plugin Maven license por cada microservicio
- CreaciÃ³n de directorio temporal `/tmp/licenses/` para reports
- Upload de artifacts desde mÃºltiples paths
- Manejo de errores graceful si plugin falla
- **Resultado:** License compliance funcionando correctamente

### 8. **Canary Deployment Failing por ValidaciÃ³n Estricta**

**Problema:** Pipeline canary fallaba si deployment no existÃ­a previamente.

**SoluciÃ³n:**
- ValidaciÃ³n mÃ¡s flexible - permite crear deployment si no existe
- Lista de deployments existentes para debugging
- Mensaje informativo en lugar de error fatal
- **Resultado:** Canary deployment funciona con servicios nuevos y existentes

---

## ğŸ“§ **CONTACTO Y SOPORTE**

**Desarrollado por:** Felipe Velasco  
**InstituciÃ³n:** Universidad Icesi  
**Curso:** Plataformas Computacionales 2  
**Fecha:** Noviembre 2025  
**Proyecto:** E-commerce Microservices Platform

**ğŸ“ UbicaciÃ³n del proyecto:** `/Users/felipevelasco79/Documents/Icesi/Plataformas2/Proyecto-Final-Google/ecommerce-microservice-backend-app/`

**ğŸ”— GitHub Repository:** https://github.com/felipevelasco7/ecommerce-microservice-backend-app

---
